# Bayes

```{r QM2-Thema2-kleineModelle-1, echo = FALSE}
library(tidyverse)
library(knitr)
library(kableExtra)
# library(flextable)
library(patchwork)
library(rethinking)
```



## Lernsteuerung

```{r chapter-start-sections, echo = FALSE, results = "asis"}
source("funs/chapter-start-sections.R")
chapter_start_sections(title = "Wahrscheinlichkeit")
```









## Kleine Welt, gro√üe Welt




### Behaims Globus, Kolumbus gl√ºcklicher Fehler

```{r QM2-Thema2-kleineModelle-4, echo = FALSE, out.width="100%" }
knitr::include_graphics("img/Behaim.jpg")
```

[Quelle](https://de.wikipedia.org/wiki/Martin_Behaims_Erdapfel#/media/Datei:RavensteinBehaim.jpg)



### Kleine Welt vs. gro√üe Welt



#### Kleine Welt 
- Die Welt, wie sie der Golem sieht
- entspricht dem Modell (zwangl√§ufig)


#### Gro√üe Welt
- Die Welt, wie sie in Wirklichkeit ist
- entspricht nicht (zwangsl√§ufig) dem Modell


:::: {.infobox .quote}
Behaims Globus ist nicht gleich der Erde. Die kleine Welt ist nicht die gro√üe Welt.
:::

Was in der kleinen Welt funktioniert, muss nicht in der gro√üen Welt funktionieren.
 Modelle zeigen immer nur die kleine Welt: Vorsicht vor schnellen Schl√ºssen und vermeintlicher Gewissheit.

üèã Nennen Sie ein Beispiel, in dem ein Modell nicht (exakt) der Wirklichkeit entspricht!

### So denkt unser Bayes-Golem


```{r QM2-Thema2-kleineModelle-5, out.width="100%", echo = FALSE}
knitr::include_graphics("img/bayesupdate2.png")
```



üèã Bayes-Inferenz √§hnelt dem Lernen von Menschen. Geben Sie ein Beispiel von Lernen bei Menschen, das oben dargestelltem Prozess √§hnelt!

## Bayes-Statistik als Z√§hlen


### Murmeln im S√§ckchen

- Sie haben ein S√§ckchen mit vier Murmeln darin. 

- Sie wissen nicht, welche Farben die Murmeln haben.

- Murmeln gibt's in zwei Farben: wei√ü (W) oder blau (B).

- Es gibt daher f√ºnf *Hypothesen* zur Farbe der Murmeln im S√§ckchen: [WWWW], [BWWW], [BBWW], [BBBW], [BBBB.]

- Unser Ziel ist, die Wahrscheinlichkeiten der Hypothesen nach Ziehen von Murmeln zu bestimmen.



```{r QM2-Thema2-kleineModelle-6, echo = FALSE, out.width="50%", echo = FALSE }

source("R-Code/img2111.R")

```




### Unsere Daten


- Wir ziehen eine Murmel, merken uns die Farbe und legen sie zur√ºck. Das wiederholen wir noch zwei Mal (Ziehen mit Zur√ºcklegen). 

- Wir erhalten: **BWB**. Voil√†: unsere Daten.

```{r QM2-Thema2-kleineModelle-7, echo = FALSE }
#knitr::include_graphics(file.path("img", "img2112.png"))
source("R-Code/img2112.R")
```


[@kurz_statistical_2021]


üèã Wie gro√ü ist die Stichprobe ($N$)? Ist die Wahrscheinlichkeit f√ºr *B* in jedem Zug gleich?


### Zugm√∂glichkeiten laut Hypothese [BWWW], 1. Zug

Wenn Hypothese [BWWW] der Fall sein sollte, dann k√∂nnen wir im *ersten* Zug entweder die eine blaue Murmel erwischen oder eine der drei wei√üen.

```{r QM2-Thema2-kleineModelle-8, echo = FALSE, out.width="70%", echo = FALSE }
#knitr::include_graphics(file.path("img", "img2113.png"))
source("R-Code/img2113.R")
```

Nachdem wir die Murmel gezogen haben (und die Farbe gemerkt haben), legen wir sie wieder ins S√§ckchen: Ziehen mit Zur√ºcklegen.


üèã Wie viele Elementarereignisse hat dieses Zufallsexperiment? Sind alle gleich wahrscheinlich?


### Zugm√∂glichkeiten laut Hypothese [BWWW], 1. und 2. Zug

Wenn Hypothese [BWWW] der Fall sein sollte, dann haben wir im *zweiten* Zug nat√ºrlich die gleichen M√∂glichkeiten wie im ersten.

Zug 1 und Zug 2 zusammen genommen gibt es $16=4\cdot4=4^2$ Kombinationen an gezogenen Murmeln:

```{r QM2-Thema2-kleineModelle-9, echo = FALSE, out.width="50%", fig.asp=.5, echo = FALSE }
#knitr::include_graphics(file.path("img", "img2113.png"))
source("R-Code/img2114.R")

```

üèã Ist jedes Elementarereignis (z.B. BB, BW,...) gleich wahrscheinlich?




### Zugm√∂glichkeiten laut Hypothese [BWWW], 1.-3. Zug



Zug 1, Zug 2 und Zug 3 zusammen genommen, gibt es dann $4\cdot4\cdot4=4^3=64$ Kombinationen, drei Murmeln zu ziehen.

```{r QM2-Thema2-kleineModelle-10, echo = FALSE, out.width="50%", echo = FALSE }
#knitr::include_graphics(file.path("img", "img2113.png"))
source("R-Code/img2115.R")
```


üèã Wie wahrscheinlich ist ein bestimmtes dieser 64 Ereignisse (unter der Annahme gleicher Wahrscheinlichkeit)?

### Welche Z√ºge sind logisch m√∂glich?


- Einige Kombinationen ("Pfade") der Hypothese [BWWW] lassen sich nicht mit unseren Daten (BWB) vereinbaren.
- Z.B. alle Kombinationen die mit W beginnen, sind nicht mit unseren Daten zu vereinbaren.

```{r QM2-Thema2-kleineModelle-11, fig.show = "hold", out.width=c("33%", "33%"), echo = FALSE}
source("R-Code/img2116.R")
source("R-Code/img2117.R")
```

Nur 3 der 64 "Pfade" (Kombinationen), die Hypothese [BWWW] vorgibt, sind mit unseren Daten logisch zu vereinbaren.

### Kombinationen f√ºr Hypothesen 

```{r QM2-Thema2-kleineModelle-12, results='asis', echo = FALSE}
source("R-Code/tab21.R")
```

- Die H√§ufigkeiten der Kombinationen (Pfade) ist proportional zur Plausibilit√§t einer Hypothese: Je mehr Pfade laut Hypothese, desto wahrscheinlicher die Hypothese (unter sonst gleichen Bedingungen).

- Zus√§tzlich m√ºssten wir noch beachten, ob bestimmte Hypothesen *per se* bzw. *a priori* wahrscheinlicher sind. So k√∂nnten blaue Murmeln selten sein. Gehen wir der Einfachheit halber zun√§chst davon aus, dass alle Hypothesen apriori gleich wahrscheinlich sind.


### Pfadbaum f√ºr die Hypothesen [BWWW], [BBWW], [BBBW]

```{r QM2-Thema2-kleineModelle-13, echo = FALSE }
knitr::include_graphics("img/img2118.png")
```


### Wir ziehen einer vierte Murmel: B

- Gehen wir zun√§chst davon aus, dass alle Hypothesen apriori gleich wahrscheinlich sind.
- Wir ziehen  wieder eine Murmel. Sie ist blau (B)!
- Jetzt k√∂nnten wir den Pfadbaum f√ºr vier (statt drei) Z√ºge aufmalen.
- Oder wir machen ein *Update*: Wir aktualisieren die bisherigen Kombinationsh√§ufigkeiten um die neuen Daten. Die *alten* Daten dienen dabei als *Priori-Informationen* f√ºr die *neuen* Daten.

### Priori-Information nutzen

Mit den Daten BWBB ist die Hypothese [BBBW] am wahrscheinlichsten:

```{r QM2-Thema2-kleineModelle-14, results = "asis", echo = FALSE}
source("R-Code/tab22.R")
```

Hyp: Hypothese

PB: Anzahl von Pfaden f√ºr B

HA: alte (bisherige) H√§ufigkeiten

HN: neue (geupdatete) H√§ufigkeiten


### Murmelfabrik streikt: Blaue Murmeln jetzt sehr selten!

- Ber√ºcksichtigen wir jetzt die Information, dass apriori (bevor wir die Daten gesehen haben), einige Hypothesen wahrscheinlicher (plausibler) sind als andere.

- Hier ist die Hypothese [BBWW] am wahrscheinlichsten:

```{r QM2-Thema2-kleineModelle-15, results = "asis", echo = FALSE}
source("R-Code/tab23.R")
```

HF: H√§ufigkeit des S√§ckchentyps laut Fabrik.



### Z√§hlen mit gro√üen Zahlen nervt

- Malen Sie mal den Pfadbaum f√ºr 10 Z√ºge ...

- Eine Umrechnung der H√§ufigkeiten in *Anteile* macht das Rechnen einfacher.

- Dazu definieren wir die *geupdatete Plausibilit√§t einer Hypothese nach Kenntnis der Daten*:

$$\text{Plausibilit√§t von [BWWW] nach Kenntnis von BWB}$$
$$\propto$$
$$\text{Anzahl m√∂glicher Pfade bei [BWWW] f√ºr BWB}$$
$$\times$$
$$\text{Priori-Plausibilit√§t von [BWWW]}$$

- $\propto$: proportional zu


### Plausibilit√§t berechnen

- Sei $p$ der Anteil blauer Murmeln. Bei Hypothese [BWWW] gilt, dann ist $p=1/4 = 0.25$. Sei $D_{neu} =$ BWB, die Daten:


$$\text{Plausibilit√§t von }p\text{ nach Kenntnis von }D_{neu}$$
$$\propto$$
$$\text{Anzahl Pfade von }p\text{ f√ºr }D_{neu}$$
$$\times$$
$$\text{Priori-Plausibilit√§t von }p$$

F√ºr jeden Wert von $p$ beurteilen wir dessen Plausibilit√§t als umso h√∂her, je mehr Pfade durch den Pfadbaum f√ºhren und je h√∂her die Plausibilit√§t des Werts von $p$ von vornherein ist.




### Von Plausibilit√§t zur Wahrscheinlichkeit

- Teilen wir die Anzahl Pfade einer Hypothese durch die Anzahl aller Pfade (aller Hypothesen), so bekommen wir einen Anteil. Damit haben wir eine Wahrscheinlichkeit:


$$\text{Pl von }p\text{ mit Daten }D_{neu} =$$
$$\frac{\text{Anzahl Pfade von }p\text{ f√ºr }D_{neu}\times \text{Prior-Pl von }p}{\text{Summe aller Pfade}}$$

Pl: Plausibilit√§t


üèã Was muss passieren, dass der Bruch gleich Null ist?

### Plausibilit√§t pro Hypothese

```{r QM2-Thema2-kleineModelle-16, results = "asis", echo = FALSE}
source("R-Code/tab24.R")
```


p: Anteil blauer Murmeln (Priori-Wissen)

AP: Anzahl von m√∂glichen Pfaden; Pl: Plausibilit√§t


```{r QM2-Thema2-kleineModelle-17, echo = TRUE}
AP <- c(0, 3, 8, 9, 0)
Pl <- AP / sum(AP)
Pl
```


### Fachbegriffe

- Kennwerte laut einer Hypothese, wie den Anteil blauer Murmeln $p$ bezeichnet man als *Parameter*.

- Den Anteil g√ºltiger Pfade pro Hypothese (bzw. pro Wert von $p$) bezeichnet man als *Likelihood*.

- Die Priori-Plausibilit√§t nennt man *Priori-Wahrscheinlichkeit*.

- Die neue, geupdatete Plausibilit√§t f√ºr einen bestimmten Wert von $p$ nennt man *Posteriori-Wahrscheinlichkeit*.


üèã Erkl√§ren Sie die Begriffe dem n√§chsten Menschen, den Sie treffen!


### Zusammenfassung


1. Schritt: Unser Vorab-Wissen zur Wahrscheinlichkeit jeder Hypothese wird mit dem Begriff *Priori-Verteilung* gefasst.

2. Schritt: Wir z√§hlen den Anteil g√ºltiger Pfade f√ºr jede Hypothese; d.h. wir berechnen den *Likelihood* jeder Hypothese.

2. Schritt: Mit den Likelihoods *updaten* wir unsere Priori-Verteilung. Die Wahrscheinlichkeit jeder Hypothese ver√§ndert sich entsprechend der Daten. Es resultiert die *Posteriori-Verteilung*.



## Ein erstes Modell

### Welcher Anteil der Erdoberfl√§che ist mit Wasser bedeckt?


```{r QM2-Thema2-kleineModelle-18, echo = FALSE, out.width = "20%"}
knitr::include_graphics("img/earth.png")
```

[Quelle](https://pngimg.com/image/25340) CC 4.0 BY-NC

Sie werden einen Globus-Ball in die Luft und fangen in wieder auf. Sie notieren dann, ob die Stelle unter Ihrem Zeigefinger Wasser zeigt (W) oder Land (L). Den Versuch wiederholen Sie 9 Mal.



$$W \quad L \quad W \quad W \quad W \quad L \quad W \quad L \quad W$$



üèã Besorgen Sie sich einen Globus (zur Not eine M√ºnze) und stellen Sie den Versuch nach!

## Der datengenierende Prozess: Wie entstanden die Daten?

1. Der wahre Anteil von Wasser der Erdoberfl√§che ist $p$.
2. Ein Wurf des Globusballes hat die Wahrscheinlichkeit $p$, eine $W$-Beobachtung zu erzeugen.
3. Die W√ºrfe des Globusballes sind unabh√§ngig voneinander.
4. Wir haben kein Vorwissen √ºber $p$; jeder Wert ist uns gleich wahrscheinlich.



üèã Welche Annahmen w√ºrden Sie √§ndern? Welche k√∂nnte man wegnehmen? Welche hinzuf√ºgen? Was w√§ren die Konsequenzen?


### Wissen updaten: Wir f√ºttern Daten in das Modell



```{r QM2-Thema2-kleineModelle-19, out.width="100%", echo = FALSE}
source("R-Code/img221.R")
```


<!-- Das Modell lernt. Ob das Modell n√ºtzlich ist (pr√§zise Vorhersagen liefert), steht auf einem anderen Blatt. -->



### Erinnern wir uns an das Urnen-Beispiel

- F√ºr jede Hypothese haben wir ein Vorab-Wissen, das die jeweilige Plausibilit√§t der Hypothese angibt: *Priori-Verteilung*.

- F√ºr jede Hypothese (d.h. jeden *Parameterwert* $p$) m√∂chten wir den Anteil (die Wahrscheinlichkeit) g√ºltiger Kombinationen wissen. Das gibt uns den *Likelihood*.

- Dann gewichten wir den Likelihood mit dem Vorabwissen, so dass wir die *Posteriori-Verteilung*^[Anstatt von *Priori* liest man auch *Prior*; anstatt *Posteriori* auch *Posterior*] bekommen.


```{r QM2-Thema2-kleineModelle-20, echo = FALSE}
knitr::include_graphics("img/bayesupdate.png")
```


### Die Binomialverteilung

Wir nehmen an, dass die Daten unabh√§ngig voneinander entstehen und sich der Parameterwert nicht zwischenzeitlich √§ndert.

Dann kann man die Wahrscheinlichkeit ($Pr$), $W$ mal Wasser und $L$ mal Land zu beobachten, wenn die Wahrscheinlichkeit f√ºr Wasser $p$ betr√§gt, mit der *Binomialverteilung* berechnen.

Die Binomialverteilung zeigt die Verteilung der H√§ufigkeit (Wahrscheinlichkeit) der Ereignisse (z.B. 2 Mal Kopf) beim wiederholten M√ºnzwurf (und allen vergleichbaren Zufallsexperimenten)^["M√ºnzwurfverteilung"].


$$Pr(W,L|p) = \frac{(W+L)!}{W!L!}p^W(1-p)^L$$


### Binomialverteilung mit R



Was ist der Anteil der g√ºltigen Pfade (Wahrscheinlichkeit), um 6 mal $W$ bei $N=W+L=9$ W√ºrfen zu bekommen, wenn wir von $p=1/2$ ausgehen?

```{r QM2-Thema2-kleineModelle-21, echo = TRUE}
dbinom(x = 6, size = 9, prob = 1/2)
```

Was ist die Wahrscheinlichkeit f√ºr $W=9$ bei $N=9$ und $p=1/2$?

```{r QM2-Thema2-kleineModelle-22, echo = TRUE}
dbinom(x = 9, size = 9, prob = 1/2)
```



### Beispiele zur Berechnung einer binomial verteilten Wahrscheinlichkeit 

Ei Professori stellt einen Klausur mit 20 Richtig-Falsch-Fragen. Wie gro√ü ist die Wahrscheinlichkeit, durch blo√ües M√ºnze werfen genau 15 Fragen richtig zu raten?^[Hey, endlich mal was f√ºr echte Leben!]


```{r QM2-Thema2-kleineModelle-23, echo = TRUE}
dbinom(x = 15, size = 20, prob = .5)
```


Was ist die Wahrscheinlichkeit bei 3 M√ºnzw√ºrfen (genau) 3 Treffer (Kopf) zu erzielen?

```{r QM2-Thema2-kleineModelle-24, echo = TRUE}
dbinom(3, 3, 1/2)
```





### Unser Modell ist geboren


Wir fassen das Globusmodell so zusammen:

$$W \sim \text{Bin}(N,p),$$

Lies: "W ist *bin*omial verteilt mit den Parametern $N$ und $p$". $N$ gibt die Anzahl der Globusw√ºrfe an: $N=W+L$.

Unser Vorab-Wissen zu $p$ sei, dass uns alle Werte gleich plausibel erscheinen ("uniform"):

$$p \sim \text{Unif}(0,1).$$

Lies: "$p$ ist gleich (uniform) verteilt mit der Untergrenze 0 und der Obergrenze 1".


### So sehen die Verteilungen aus



#### Binomialverteilung

```{r QM2-Thema2-kleineModelle-25, echo = FALSE}
dbinom(0:9, 9, 1/2) %>% 
  tibble(Wahrscheinlichkeit = .,
         Treffer = seq(0,9)) %>% 
  ggplot(aes(x = Treffer, y = Wahrscheinlichkeit)) +
  geom_segment(aes(xend = Treffer, yend = 0)) + 
  geom_point(color = "red", size = 5, alpha = .5) +
  scale_x_continuous(breaks = 0:9)

```

$N=9, p = 1/2$


#### Gleichverteilung

```{r QM2-Thema2-kleineModelle-26, echo = FALSE}

uniform_Plot <- function(a, b){
  xvals <- data.frame(x = c(a, b)) #Range for x-values
  
  ggplot(data.frame(x = xvals), 
         aes(x = x)) + xlim(c(a, b)) + ylim(0, 1/(b - a)) +
    stat_function(fun = dunif, args = list(min = a, max = b), 
                  geom = "area", 
                  fill = "green", alpha = 0.35) + 
    stat_function(fun = dunif, args = list(min = a, max = b)) +
    labs(x = "X", y = "Dichte")  +
    geom_vline(xintercept = a, linetype = "dashed", colour = "red") +
    geom_vline(xintercept = b, linetype = "dashed", colour = "red") 
  
}
uniform_Plot(0, 1)
```

$Min = 0, Max = 1$




üèã Was f√§llt Ihnen bei der Binomialverteilung auf? Ist sie symmetrisch? Ver√§ndert sich die Wahrscheinlichkeit linear? Was f√§llt Ihnen bei der Gleichverteilung auf?


### Herleitung Bayes' Theorem 1/2: Gemeinsame Wahrscheinlichkeit

Die Wahrscheinlichkeit f√ºr *Regen* und *kalt* ist gleich der Wahrscheinlihckeit von *Regen*, *gegeben kalt* mal der Wahrscheinlicht von *kalt*. Entsprechend gilt: Die Wahrscheinlichkeit von $W$, $L$ und $p$ ist das Produkt von $Pr(W,L|p)$ und der Prior-Wahrscheinlichkeit $Pr(p)$:

$$Pr(W,L,p) = Pr(W,L|p) \cdot Pr(p)$$

Genauso gilt: Die Wahrscheinlichkeit von *Regen* und *kalt* ist gleich der Wahrscheinlichkeit *kalt, wenn's regnet* mal der Wahrscheinlichkeit von *Regen*:

$$Pr(W,L,p) = Pr(p|W,L) \cdot Pr(W, L)$$



### Herleitung Bayes' Theorem 2/2: Posteriori-Wahrscheinlichkeit

Wir setzen die letzten beiden Gleichungen gleich:

$$Pr(W,L|p) \cdot Pr(p) = Pr(p|W,L) \cdot (W,L)$$

Und l√∂sen auf nach der Posteriori-Wahrscheinlichkeit, $Pr(p|W,L)$:

$$Pr(p|W,L) = \frac{Pr(W,L|p) Pr(p)}{Pr(W,L)}$$


$Pr(W,L)$ nennt man die *mittlere Wahrscheinlichkeit der Daten* oder *Evidenz*. Die Evidenz berechnet sich als Mittelwert der Likelihoods √ºber alle Werte von $p$. Die Aufgabe dieser Gr√∂√üe ist nur daf√ºr zu sorgen, dass insgesamt Werte zwischen 0 und 1 herauskommen.


### Bayes' Theorem



\begin{alertblock}{Formel Bayes' Theorem}
$$Pr(H|D) = \frac{Pr(D|H) Pr(H)}{Pr(D)}$$
\end{alertblock}




- Bestandteile:

    - Posteriori-Wahrscheinlichkeit: $Pr_{Post}  := Pr(H|D)$

    - Likelihood: $L := Pr(D|H)$

    - Priori-Wahrscheinlichkeit: $Pr_{Priori} := Pr(H)$

    - Evidenz: $E := Pr(D)$

- Bayes' Theorem gibt die $Pr_{Post}$ an, wenn man die Gleichung mit der $Pr_{Priori}$ und dem $L$ f√ºttert.

- Bayes' Theorem wird h√§ufig verwendet, um die $Pr_{Post}$ zu quantifizieren. 

- Die $Pr_{Post}$ ist proportional zu $L \times Pr_{Priori}$.




### Posteriori als Produkt von Priori und Likelihood

$$\text{Posteriori} = \frac{\text{Likelihood} \times \text{Priori}}{\text{Evidenz}}$$

```{r QM2-Thema2-kleineModelle-27, echo = FALSE}
source("R-Code/img241.R")
```




## Bayes berechnen mit R


### Die Methode *Gitter-Ann√§herung*^[Grid Approximation]

1. Teile den Wertebereich des Parameter in ein "Gitter" auf, z.B. $0.1, 0.2, ..., 0.9, 1$ ("Gitterwerte").
2. Bestimme den Priori-Wert des Parameters f√ºr jeden Gitterwert.
3. Berechne den Likelihood f√ºr Gitterwert.
4. Berechne den unstandardisierten Posteriori-Wert f√ºr jeden Gitterwert (Produkt von Priori und Likelihood).
5. Standardisiere den Posteriori-Wert durch teilen anhand der Summe alle unstand. Posteriori-Werte.


### Gitterwerte in R berechnen


```{r QM2-Thema2-kleineModelle-28, echo = TRUE}
d <-
  tibble(
    # definiere das Gitter: 
    p_Gitter = seq(from = 0, to = 1, length.out = 10),
    # bestimme den Priori-Wert:       
    Priori  = 1) %>%  
    mutate(
      # berechne Likelihood f√ºr jeden Gitterwert:
      Likelihood = dbinom(6, size = 9, prob = p_Gitter),
      # berechen unstand. Posteriori-Werte:
      unstd_Post = Likelihood * Priori,
      # berechne stand. Posteriori-Werte (summiert zu 1):
      Post = unstd_Post / sum(unstd_Post))  
```



### Unsere Gitter-Daten

```{r QM2-Thema2-kleineModelle-29, echo = FALSE}
d %>% 
  kbl(digits = 2)
```


üèã Was wohl mit *Post* passiert, wenn wir *Priori* √§ndern?



### $Pr_{Post}$ zeigt, wie plausibel wir jeden Wert von $p$ halten


```{r QM2-Thema2-kleineModelle-30, out.width="100%", echo = FALSE}
source("R-Code/img242.R")
```


Mehr Gitterwerte gl√§tten die Ann√§herung.

<!-- ### Quadratische Anpassung^[Quadratic Approximation] -->

<!-- - Komfortabler noch ist die *quadratische Anpassung*, die bestimmte statistische Eigenschaften von linearen Modellen ausnutzt. -->

<!-- - Der R-Befehl `quap` gibt zentrale Statistiken zu den Parametern des Modells zur√ºck. -->


<!-- ```{r QM2-Thema2-kleineModelle-31, echo = TRUE} -->
<!-- library(rethinking) -->

<!-- globus_qa <- quap(  # "quadratic approximation" -->
<!--   alist(  # definiere die Modellgleichungen -->
<!--     W ~ dbinom(W + L, p),  # Likelihood ist binomial verteilt -->
<!--     p ~ dunif(0, 1)        # Priori ist gleich (uniform) verteilt -->
<!--   ),  -->
<!--   data = list(W = 6, L = 3)  # Daten -->
<!-- ) -->


<!-- precis(globus_qa)  # Gibt uns die zentralen Ergebnisse -->
<!-- ``` -->




### Je gr√∂√üer die Stichprobe ($N$), desto zuverl√§ssiger wird unsere Berechnung

```{r QM2-Thema2-kleineModelle-32, out.width="100%", echo = FALSE}
source("R-Code/img243.R")
```

Grau: Quadratische Anpassung; schwarz: wahre Verteilung


### Zusammenfassung

- In unserem Modell haben wir Annahmen zu $Pr_{Priori}$ und $L$ getroffen.

- Auf dieser Basis hat der Golem sein Wissen geupdated zu $Pr_{Post}$.

- Mit der Gitter-Methode haben wir viele Hypothesen (Parameterwerte) untersucht und jeweils die $Pr_{Post}$ berechnet.

- Unser Modell bildet die kleine Welt ab; ob es in der gro√üen Welt n√ºtzlich ist, steht auf einem anderen Blatt.


üèã Wenn Sie auf einen Prozentwert f√ºr $W$ tippen m√ºssten, welchen w√ºrden Sie nehmen, laut dem Modell (und gegeben der Daten)?






## Literatur







